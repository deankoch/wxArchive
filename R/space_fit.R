#' Fit a spatial covariance model to a NetCDF time series
#'
#' This uses `snapKrig` to fit a spatial MVN covariance model to a random
#' subsample of the layers in a NetCDF file (up to `n_max`). The covariates matrix
#' is generated by passing the DEM at `dem_path `to `space_X`. It includes a
#' spline basis for lapse rate, and columns for geographic coordinates.
#'
#' This uses a purely spatial geo-statistical model with a nugget effect, and a
#' stationary Gaussian covariogram with geometric anisotropy oriented along the
#' cardinal axes. Time layers are treated as mutually independent, and the function
#' uses a random subsample (<=`n_max`) of times for model fitting.
#'
#' Subsampling excludes layers with any number of NAs. when `positive=TRUE`, it also
#' excludes all-zero layers (useful for precipitation). When `positive=NULL` (the
#' default), the function attempts to detect precipitation layers automatically by
#' setting `positive=TRUE` for variable names beginning with 'pcp'.
#'
#' `input_nc` can be a vector of sub-directories, and `var_nm` can be a list of
#' character vectors (specifying sets of equivalent names), allowing users to specify
#' multiple source files for a single variable, similar to `nc_resample`.
#'
#' Variable names (`var_nm`) specify a subset of the nc files in `input_nm` to process
#' in a loop. The results are written to a JSON file in sub-directory "model" of the first
#' sub-directory listed in `input_nm`. Get the list of all output paths with:
#'
#' `file_wx('spatial', base_dir, input_nm[1], as.list(names(var_nm))`
#'
#' Model fit information is appended to the bottom of the existing list in the JSON file.
#' The results include the output of helper function `run_spatial_fit`, along with the
#' time of the function call, and the input files and variable names.
#'
#' @param var_nm character vector or list, the names of the variables to fit (in a loop)
#' @param base_dir path to parent directory of GRIB storage subfolder
#' @param dem_path character path to the DEM (passed to `terra`)
#' @param input_nm character vector or list, subdirectories containing the .nc files to fit
#' @param model_nm character name of sub-directory to write output files
#' @param n_max integer, maximum number of layers to sample for fitting
#' @param positive logical indicating to exclude all-zero layers
#'
#' @return returns nothing, but writes to JSON files in sub-directory `train_nm` of `base_dir`
#' @export
spatial_fit = function(var_nm,
                       base_dir,
                       dem_path,
                       input_nm = 'fine',
                       model_nm = input_nm[[1]],
                       n_max = 5e2,
                       positive = NULL) {

  # input and output paths
  input_nc = file_wx('nc', base_dir, input_nm, var_nm)
  var_nm = var_nm |> stats::setNames(nm=names(input_nc))
  output_path = file_wx('spatial', base_dir, input_nm[1], as.list(names(var_nm)), make_dir=TRUE)

  # get grid info from first nc file, and spatial covariates matrix from DEM and grid dimensions
  cat('\nconstructing covariates from', dem_path)
  r_grid = input_nc[[1]][1] |> terra::rast(lyrs=1) |> terra::rast()
  X_space = space_X(r=r_grid, dem=terra::rast(dem_path))

  # load time coverage of each variable
  cat('\nreading times and grid information for', paste(names(var_nm), collapse=', '))
  var_info = input_nc |> lapply(\(p) time_wx(p))

  # fit spatial model for each variable in a loop
  cat('\nfitting spatial models...')
  for( v in seq_along(var_nm) ) {

    # load existing JSON data as list (or create the file)
    cat('\n\nprocessing', names(var_nm)[v])
    t1 = proc.time()
    json_exists = file.exists(output_path[[v]])
    if( !json_exists ) writeLines('[]', output_path[[v]])
    out_list = output_path[[v]] |> readLines() |> jsonlite::fromJSON()

    # fit the model and append results to existing list
    fit_result = input_nc[[v]] |> run_spatial_fit(X=X_space, n_max=n_max, positive=positive)
    append_list = list(var_nm = var_nm[[v]], sub_dir = input_nm) |> c(fit_result) |> list()
    out_list = out_list |> c(append_list)
    names(out_list) = paste0('fit_', seq_along(out_list))

    # write to existing JSON
    cat('\nwriting results to', output_path[[v]])
    out_list |> jsonlite::toJSON(pretty=TRUE) |> writeLines(output_path[[v]])

    t2 = proc.time()
    cat('\nfinished in', round((t2-t1)['elapsed'] / 60, 2), 'minutes.')
  }
}


#' Fit a spatial model and return a list of results for use in `spatial_fit`
#'
#' This is a helper function for `spatial_fit`. It fits a random subsample of
#' the observed data (from `p`) using the covariates in `X`. Generate `X` by passing
#' an example grid from `p` (along with a DEM) to `space_X`.
#'
#' The function returns a list with the following
#'
#' * at : the UTC time of the function call
#' * file : the files containing the sampled input data
#' * pars : fitted parameters in a snapKrig-friendly list
#' * bds : parameter bounds (lower, initial, fitted, upper)
#' * betas : GLS estimates of the linear model coefficients
#' * train : the times in the training set
#'
#' @param p character vector of input file paths to time series .nc files
#' @param X numeric matrix of spatial covariates (output of `space_X`)
#' @param n_max integer > 0 number of layers to sample
#' @param t_fit character vector of POSIXct times to sample
#' @param positive logical indicating to exclude all-zero layers
#'
#' @return list of model fitting results
#' @export
run_spatial_fit = function(p, X, n_max=1e2, t_fit=NULL, positive=NULL) {

  # by default select non-zero layers only for variable names starting with "pcp"
  if( is.null(positive) ) positive = basename(p) |> startsWith('pcp') |> any()

  # add POSIXct time of function call to result
  call_time = Sys.time() |> as.character(tz='UTC')

  # load attributes for the nc file(s)
  nc_info = time_wx(p)
  t_all = nc_info[['time']]
  t_obs = nc_info[['time_obs']]

  # select a set of points at random if idx_fit not supplied
  n_fit = length(t_fit)
  if( is.null(t_fit) ) {

    # sample from remaining times
    n_fit = t_obs |> length() |> pmin(n_max)
    t_fit = t_obs |> sample(n_fit) |> sort()
  }

  # copy non-NA layers and times into memory as sk object
  msg_n = paste0('(sampled from ', length(t_obs), ')')
  cat('\nloading', n_fit, 'layers', msg_n)
  g_fit = p |> nc_layers(t_fit, na_rm=TRUE) |> snapKrig::sk()

  # filter to times where the grid had non-zero value
  if( positive ) {

    # check for layers with no nonzero values
    cat('\nchecking for all-zero layers')
    is_zero = g_fit[] |> apply(2, \(x) all(x == 0))
    if( all(is_zero) ) stop('no non-zero layers!')

    # filter to analyze only nonzero layers
    g_fit = snapKrig::sk(g_fit, vals=FALSE) |> snapKrig::sk(gval=g_fit[][, !is_zero])
    t_fit = t_fit[!is_zero]
    n_fit = length(t_fit)
  }

  # fit a model then remove observed layers from memory
  cat('\nfitting spatial covariance to', n_fit, 'layers')
  pars = g_fit |> snapKrig::sk_fit(pars='gau', X=X, iso=FALSE, quiet=TRUE)
  gls = g_fit |> snapKrig::sk_GLS(pars, X=X, out='b')
  rm(g_fit)
  gc()

  # reshape bounds matrix as list of vectors
  bds = as.matrix(attr(pars, 'bds')) |> apply(1, identity, simplify=FALSE)

  # return training times and fitted parameters in a list
  return( list(at = call_time,
               file = p,
               pars = pars,
               bds = bds,
               betas = gls,
               train = t_fit) )
}
