#' Fit a spatial covariance model to a NetCDF time series
#' 
#' This uses `snapKrig` to fit a spatial MVN covariance model to a random
#' subsample of the layers in a NetCDF file (up to `n_max`). The covariates matrix
#' is generated by passing the DEM at `dem_path `to `my_space_X`. It includes a
#' spline basis for lapse rate, and columns for geographic coordinates.
#' 
#' This uses a purely spatial geo-statistical model with a nugget effect, and a
#' stationary Gaussian covariogram with geometric anisotropy (oriented along the
#' cardinal axes). Time layers are treated as mutually independent, and the function
#' uses a random subsample (<=`n_max`) of times for model fitting.
#' 
#' Subsampling excludes layers with any number of NAs. when `positive=TRUE`, it also
#' excludes all-zero layers (useful for precipitation). When `positive=NULL` (the
#' default), the function detects precipitation layers automatically (and sets
#' `positive=TRUE`) by checking if any of the variable names begin with 'pcp'.
#' 
#' `input_nc` can be a vector of sub-directories, and `var_nm` can be a list of
#' character vectors (specifying sets of equivalent names), allowing users to specify
#' multiple source files for a single variable, similar to `my_resample`.
#' 
#' Variable names (`var_nm`) specify a subset of the nc files in `input_nm` to process
#' in a loop. The results are written to a JSON file in sub-directory "model" of the first
#' sub-directory listed in `input_nm`. Get the list of all output paths with:
#' 
#' `file_wx('spatial', base_dir, input_nm[1], as.list(names(var_nm))`
#' 
#' If `append=FALSE` the function deletes any existing data in the JSON and replaces
#' it with the new model fit. If `append=TRUE`, the new fit is appended to the bottom of
#' the existing list in the file. The results include the output of `my_sk_fit`, along
#' with the time of the function call, and the input files and variable names.
#' 
#' @param var_nm character vector or list, the names of the variables to fit (in a loop)
#' @param base_dir path to parent directory of GRIB storage subfolder
#' @param dem_path character path to the DEM (passed to `terra`)
#' @param input_nm character vector or list, subdirectories containing the .nc files to fit
#' @param n_max integer, maximum number of layers to sample for fitting
#' @param append logical indicating to keep old model fits in the JSON
#' @param positive logical indicating to exclude all-zero layers
#'
#' @return returns nothing, but writes to JSON files in `file.path(base_dir, train_nm)`
#' @export
my_fit_spatial = function(var_nm,
                          base_dir,
                          dem_path,
                          input_nm = 'fine',
                          n_max = 5e2,
                          append = TRUE,
                          positive = NULL) {
  
  # input and output paths
  input_nc = file_wx('nc', base_dir, input_nm, var_nm)
  var_nm = var_nm |> stats::setNames(nm=names(input_nc))
  output_path = file_wx('spatial', base_dir, input_nm[1], as.list(names(var_nm)), make_dir=TRUE)
  
  # get grid info from first nc file, and spatial covariates matrix from DEM and grid dimensions
  cat('\nconstructing covariates from', dem_path)
  r_grid = input_nc[[1]][1] |> terra::rast(lyrs=1) |> terra::rast()
  X_space = my_space_X(r_grid, terra::rast(dem_path))
  cat(' \U2713')
  
  # load time coverage of each variable 
  cat('\nreading times and grid information for', paste(names(var_nm), collapse=', '))
  var_info = input_nc |> lapply(\(p) my_nc_attributes(p, ch=TRUE))
  cat(' \U2713')
  
  # fit spatial model for each variable in a loop
  cat('\nfitting spatial models...')
  for( v in seq_along(var_nm) ) {
    
    # load existing JSON data as list (creates the file)
    cat('\n\nprocessing', names(var_nm)[v])
    t1 = proc.time()
    json_exists = file.exists(output_path[[v]])
    if( !json_exists | !append ) writeLines('[]', output_path[[v]])
    out_list = output_path[[v]] |> readLines() |> jsonlite::fromJSON()
    
    # fit the model and append results to existing list
    fit_result = input_nc[[v]] |> my_sk_fit(X=X_space, n_max=n_max, positive=positive)
    append_list = list(var_nm = var_nm[[v]], sub_dir = input_nm) |> c(fit_result) |> list()
    out_list = out_list |> c(append_list)
    names(out_list) = paste0('fit_', seq_along(out_list))
    
    # write to existing JSON
    cat('\nwriting results to', output_path[[v]])
    out_list |> jsonlite::toJSON(pretty=TRUE) |> writeLines(output_path[[v]])
    cat(' \U2713')
    t2 = proc.time()
    cat('\nfinished in', round((t2-t1)['elapsed'] / 60, 2), 'minutes.')
  }
}


#' Fit a spatial model and return a list of results for use in `my_fit_spatial`
#' 
#' This is a helper function for `my_fit_spatial`. It fits a random subsample of
#' the observed data (from `p`) using the covariates in `X`. Generate `X` by passing
#' an example grid from `p` (along with a DEM) to `my_space_X`.
#' 
#' The function returns a list with the following
#' 
#' * at : the UTC time of the function call
#' * file : the files containing the sampled input data 
#' * pars : fitted parameters in a snapKrig-friendly list
#' * bds : parameter bounds (lower, initial, fitted, upper)
#' * betas : GLS estimates of the linear model coefficients 
#' * train : the times in the training set
#'
#' @param p character vector of input file paths to time series .nc files 
#' @param X numeric matrix of spatial covariates (output of `my_space_X`)
#' @param n_max integer > 0 number of layers to sample
#' @param t_fit character vector of POSIXct times to sample
#' @param positive logical indicating to exclude all-zero layers
#'
#' @return list of model fitting results
#' @export
my_sk_fit = function(p, X, n_max=1e2, t_fit=NULL, positive=NULL) {
  
  # by default select non-zero layers only for variable names starting with "pcp"
  if( is.null(positive) ) positive = basename(p) |> startsWith('pcp') |> any()
  
  # add POSIXct time of function call to result
  call_time = Sys.time() |> as.character(tz='UTC')
  
  # load attributes for the nc file(s)
  nc_info = my_nc_attributes(p, ch=TRUE)
  t_all = nc_info[['time']]
  t_obs = nc_info[['time_obs']]
  
  # select a set of points at random if idx_fit not supplied
  n_fit = length(t_fit)
  if( is.null(t_fit) ) {
    
    # sample from remaining times
    n_fit = t_obs |> length() |> pmin(n_max)
    t_fit = t_obs |> sample(n_fit) |> sort()
  }
  
  # copy non-NA layers and times into memory as sk object
  msg_n = paste0('(subsample of ', length(t_obs), ')')
  cat('\ncopying data from', n_fit, 'layers', msg_n)
  g_fit = nc_layers(p, t_fit) |> snapKrig::sk()
  cat(' \U2713')
  
  # filter to times where the grid had non-zero value
  if( positive ) {
    
    # check for all-zero layers (or NAs) - this loads all layers into memory
    cat('\nchecking for all-zero layers')
    is_zero = g_fit[] |> apply(2, \(x) all(x == 0))
    if( all(is_zero) ) stop('no non-zero layers!')
    
    # filter to analyze only non-zero layers
    g_fit = snapKrig::sk(g_fit, vals=FALSE) |> snapKrig::sk(gval=g_fit[][, !is_zero])
    t_fit = t_fit[!is_zero]
    n_fit = length(t_fit)
    cat(' \U2713')
  }
  
  # fit a model 
  cat('\nfitting spatial covariance to', n_fit, 'layers')
  pars = g_fit |> snapKrig::sk_fit(pars='gau', X=X, iso=FALSE, quiet=TRUE)
  gls = g_fit |> snapKrig::sk_GLS(pars, X=X, out='b')
  cat(' \U2713')
  
  # reshape bounds matrix as list of vectors 
  bds = as.matrix(attr(pars, 'bds')) |> apply(1, identity, simplify=FALSE)
  
  # return training times and fitted parameters in a list
  return( list(at = call_time, 
               file = p,
               pars = pars,
               bds = bds,
               betas = gls,
               train = t_fit) )
}



#' Return a data matrix of spatial linear predictors given target grid and a DEM
#' 
#' This creates predictors for Northing and Easting (or latitude and longitude),
#' as well as a spline basis for the lapse rate effect. All columns are centered
#' and scaled by standard deviation, in that order.
#' 
#' The output matrix has a row for each (spatial) point in `r` and a column for
#' every predictor (`1 + length(dem_knots)`, with default `intercept=FALSE`).
#' Rows are in the column major ordering used by `snapKrig` (but not `terra`).
#' 
#' The centering/scaling constants and the spline knots are provided in attributes
#' of the returned matrix. These can be copied and passed back to this function in
#' subsequent calls with a different `dem` or `r`. This will ensure that your fitted
#' `betas` are scaled properly when predicting at unseen locations.
#' 
#' It is assumed that `dem` covers the extent of `r`. `dem` can have a different
#' projection than `r`, but (for best results) it should have a much finer resolution.
#' 
#' The spline basis is created using `splines::ns`. If `dem_knots` is supplied,
#' it should include boundary points. If it is not supplied, the function puts
#' knots at the default `quantile` values of `dem`, after cropping `dem` to the
#' extent of `r` (but before resampling).
#'
#' @param r SpatRaster providing the target grid (data layers are ignored)
#' @param dem SpatRaster of elevation data at finer resolution than `r`
#' @param dem_knots numeric vector of elevation knot locations (in metres)
#' @param X_center numeric vector of centering constants
#' @param X_scale numeric vector of scaling constants
#' @param intercept logical indicating to include an intercept column (of `1`s)
#'
#' @return a matrix of covariates
#' @export
my_space_X = function(r, dem, dem_knots=NULL, X_center=NULL, X_scale=NULL, intercept=FALSE) {
  
  # use bilinear averaging to project onto forecast grid
  dem_warp = dem |> terra::project(r) |> snapKrig::sk()
  
  # get dem_knots (if not supplied) from quantiles of dem
  if( is.null(dem_knots) ) {
    
    bbox_crop = sf::st_bbox(r) |> sf::st_as_sfc() |> sf::st_transform(terra::crs(dem))
    dem_crop = dem |>  terra::crop(as(bbox_crop, 'Spatial')) |> snapKrig::sk()
    dem_knots = dem_crop |> quantile()
  }
  
  # make a spline basis for the DEM
  dem_knots_inner = dem_knots |> head(-1) |> tail(-1)
  dem_basis = dem_warp[] |> splines::ns(knots=dem_knots_inner, Boundary.knots=range(dem_knots))
  colnames(dem_basis) = paste0('dem_spline_', colnames(dem_basis))
  
  # other simple covariates
  northing = snapKrig::sk(dem_warp, gval=snapKrig::sk_coords(dem_warp, out='list', quiet=T)[['y']])
  easting = snapKrig::sk(dem_warp, gval=snapKrig::sk_coords(dem_warp, out='list', quiet=T)[['x']])
  
  # combine into spatial covariates matrix, scale columns 
  X_space_unscaled = cbind(y = northing[], x = easting[], dem_basis)
  if( is.null(X_center) ) X_center = X_space_unscaled |> apply(2, mean, na.rm=TRUE)
  X_space = X_space_unscaled |> sweep(2, X_center)
  if( is.null(X_scale) ) X_scale = X_space |> apply(2, sd, na.rm=TRUE)
  X_space = X_space |> sweep(2, X_scale, '/')
  colnames(X_space) = colnames(X_space_unscaled)
  
  # add intercept column if requested
  if( intercept ) X_space = cbind(rep(1, nrow(X_space)), X_space)
  
  # copy attributes from scaling and splines to output
  attr(X_space, 'Boundary.knots') = attr(dem_basis, 'Boundary.knots')
  attr(X_space, 'knots') = attr(dem_basis, 'knots')
  attr(X_space, 'center') = X_center
  attr(X_space, 'scale') = X_scale
  return(X_space)
}
