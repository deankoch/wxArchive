% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/helpers_workflow.R
\name{my_update_nc}
\alias{my_update_nc}
\title{Create or update a NetCDF version of a local RAP archive}
\usage{
my_update_nc(
  aoi,
  base_dir,
  output_nm = list(coarse = c("coarse"), fine = c("fine")),
  regex = .rap_regex,
  n_chunk = 5000,
  memory_limit = 8L,
  make_dummy = FALSE,
  from = NULL,
  append = TRUE
)
}
\arguments{
\item{aoi}{geometry object passed to \code{my_grib_idx} (area of interest)}

\item{base_dir}{path to parent directory of GRIB storage subfolder}

\item{output_nm}{list of character vectors, sub-directories in \code{base_dir} for the nc files}

\item{regex}{character vector passed to \code{my_grib_idx} (layer names)}

\item{n_chunk}{number of files to load before saving intermediate results to disk}

\item{memory_limit}{integer (GB) maximum memory usage passed to \code{my_grib_extract}}

\item{make_dummy}{logical, indicates to omit "pcp_total" for early years (see details)}

\item{from}{POSIXct time or vector of them, GRIB files for this and all earlier times are ignored}
}
\value{
nothing, but possibly writes to the nc and JSON files in \code{file.path(base_dir, output_nm)}
}
\description{
Most GRIB files fetched by \code{my_update_archive} are around 20-30 MB compressed,
so loading tens of thousands at once is extremely slow. To make the time series
easier to work with, this function extracts the subset that we need and saves it in
a format that can be loaded more quickly.
}
\details{
The function opens the GRIB files in the time series created by \code{my_update_archive}
and merges the data into a single (multi-layer) NetCDF file for each of the variables
selected by \code{regex}. Only the sub-grid overlapping with \code{aoi} is copied.

The output files are given base names \code{names(regex)}, and extension '.nc', and
have layers named after the POSIXct time (as character, in GMT) at which the
forecast is valid. To see the paths of the output nc files, do:

\code{wx_file('nc', base_dir, output_nm, regex)}

RAP/RUC GRIBS come in two resolutions, so these are processed separately and saved
to separate sub-directories, named in \code{output_nm}. This means there are two output
nc files per variable: the primary 13km grid series ("fine"), and the much smaller
25km series ("coarse").

\code{output_nm} should be a list with entries 'coarse' and/or 'fine', each containing
one or more subdirectory names. This is to allow users to store a small nc file
for relatively new data separately from one or more "archived" nc files that are
unlikely to change very often. The function always writes to the first subdirectory
named in each of the elements of \code{output_nm}, but all subdirectories are checked
when determining if a time has been processed yet.

If \code{from} is supplied, the function only copies new times greater than or equal to
\code{from}. A different \code{from} can be specified for each variable, in which case
\code{length(from)} should match \code{length(regex)}. By default, \code{from} is set to the
earliest available time.

The default \code{append=TRUE} only copies data from files whose time does not already
appear in the existing files listed in \code{output_nm}. With \code{append=FALSE}, the function
copies all times greater than or equal to \code{from}, overwriting any existing times in
the output nc files (any existing times before \code{from} will remain).

Within each of these sub-directories, another sub-directory, 'time', is created
to store JSON files, one per variable (ie one per nc file). These hold the indices
of NA layers, and the observed times, for quicker loading later on. To see their
output paths. do:

\code{wx_file('index', base_dir, output_nm, regex)}

The script will be very slow on the initial run with many input GRIBs, but subsequent
calls to update an existing set of nc files (and JSONs) will be much faster, as
only the missing layers are read and copied, and the files to modify on disk are
relatively small.

Note that total precipitation \code{.rap_regex['pcp_total']}is not available for the
first decade or so. By default the function creates a dummy nc file (empty of
data) for this period to avoid unnecessarily loading GRIBs to look for it. This
behaviour can be switched off with \code{make_dummy=FALSE}.
}
